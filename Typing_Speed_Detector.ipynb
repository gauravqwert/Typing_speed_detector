{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hDz193Rm_eHx",
        "outputId": "bf53f00f-a0d9-4c51-ee3d-d738753fd912",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset...\n",
            "Dataset generated in 0.01 seconds\n",
            "Training model...\n",
            "Model trained in 0.15 seconds\n",
            "Model Accuracy: 1.00\n",
            "Model saved as 'typing_speed_model.joblib'\n",
            "\n",
            "Feature Importances:\n",
            "wpm: 0.343\n",
            "avg_pause: 0.443\n",
            "pause_std: 0.205\n",
            "error_rate: 0.007\n",
            "total_chars: 0.001\n"
          ]
        }
      ],
      "source": [
        "# Typing Speed Detector - Optimized CPU Version\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "# Generate synthetic typing data more efficiently\n",
        "def generate_typing_data(num_samples=1000):\n",
        "    data = []\n",
        "    target = []\n",
        "    sentences = [\n",
        "        \"The quick brown fox jumps over the lazy dog.\",\n",
        "        \"Pack my box with five dozen liquor jugs.\",\n",
        "        \"How vexingly quick daft zebras jump!\",\n",
        "        \"Bright vixens jump; dozy fowl quack.\",\n",
        "        \"Sphinx of black quartz, judge my vow.\"\n",
        "    ]\n",
        "\n",
        "    # Pre-calculate sentence lengths\n",
        "    sentence_lengths = [len(s) for s in sentences]\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Select a random sentence\n",
        "        idx = random.randint(0, len(sentences)-1)\n",
        "        sentence = sentences[idx]\n",
        "        chars = len(sentence)\n",
        "\n",
        "        # Simulate typing metrics without actual delays\n",
        "        # Generate random WPM between 20-120\n",
        "        wpm = random.uniform(20, 120)\n",
        "\n",
        "        # Calculate derived metrics based on WPM\n",
        "        total_time = (chars / 5) / (wpm / 60)  # Reverse calculate time from WPM\n",
        "        avg_pause = total_time / chars\n",
        "        pause_std = avg_pause * random.uniform(0.8, 1.2)\n",
        "        error_rate = random.uniform(0, 0.1)\n",
        "\n",
        "        # Categorize typing speed\n",
        "        if wpm < 30:\n",
        "            speed_class = 'slow'\n",
        "        elif 30 <= wpm < 60:\n",
        "            speed_class = 'moderate'\n",
        "        else:\n",
        "            speed_class = 'fast'\n",
        "\n",
        "        data.append([wpm, avg_pause, pause_std, error_rate, chars])\n",
        "        target.append(speed_class)\n",
        "\n",
        "    return pd.DataFrame(data, columns=['wpm', 'avg_pause', 'pause_std', 'error_rate', 'total_chars']), target\n",
        "\n",
        "# Generate dataset (500 samples is sufficient for good accuracy)\n",
        "print(\"Generating dataset...\")\n",
        "start_time = time.time()\n",
        "X, y = generate_typing_data(500)\n",
        "print(f\"Dataset generated in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model with optimized parameters\n",
        "print(\"Training model...\")\n",
        "start_time = time.time()\n",
        "model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)  # Reduced complexity\n",
        "model.fit(X_train, y_train)\n",
        "print(f\"Model trained in {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, 'typing_speed_model.joblib')\n",
        "print(\"Model saved as 'typing_speed_model.joblib'\")\n",
        "\n",
        "# Feature importance analysis (optional)\n",
        "importances = model.feature_importances_\n",
        "features = X.columns\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature, importance in zip(features, importances):\n",
        "    print(f\"{feature}: {importance:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0Wd5Awv_hgW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}